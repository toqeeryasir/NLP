{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432,
     "referenced_widgets": [
      "3faa3fe7dede496db45411f0c154719c",
      "bb153b880057445e96771b5488cae71f",
      "86e18be60ff44650b62a0daf5732602f",
      "ec65d65377db4b5897234dcceec5ba1b",
      "d958fa4f635d47c08155355c8871ab43",
      "ef8e0b7dca574b1fb27ecf7ca4b424e9",
      "f01346c9bca74a0e89284453abc216b6",
      "287674887ea84702a353bd8939028d49",
      "1dd72ca811a247a88875329379230355",
      "9b6d43e0600d473eb58cb4569b805847",
      "d344bfd62eac4f5ca3507fb12e5d6d4c",
      "f7a17b3320234408b75833e384be24b7",
      "c2a8d60619e3417dac21d4979b38019e",
      "ae8d962961424f018f21cfe1deba9c47",
      "4670af1e180e4b9d8fca5427be80db70",
      "3cf0bd4f9bbd42c1959cb00070782cf8",
      "13211e1424b9415c825a20bbc63dd0fc",
      "cd7438d1fb464450a5be51f53e0e2e6f",
      "c55e0f1a45b24a778d051af2604e46b5",
      "254521e41cad496fbc2e8d6d6ec3c51f",
      "bc4b4d55c7dc4c399c5b6d802204ecf0",
      "60a5a024b6ce42938d74f15a4650bdb4",
      "e42da4aa416846099da0ac9950a4c747",
      "8fbca1dfa9f4422e84886115f2f930c0",
      "ab7503be81e14365ab7760cb90876071",
      "00d5e810463b4084a39494e96f4459c8",
      "c1e01a60c7e0453b953a689b4e85e470",
      "8e1fc09c5ed34ca6baa92eed656dc37f",
      "bf871decdf0a43dba7b194c8945352f9",
      "f4c34d9db9e6469e9660db443ecc18a3",
      "8379b3a95f5d4528886878cf8210cc7e",
      "1008c903b3144d1282df9e0cb8a124c4",
      "6b3ba468499640758675ee3ca85da097",
      "9a352818d17c48afbebf96b16e97e15c",
      "c02766c796cb467b9add50d4d05cfc2c",
      "3c648bf986be4bdca12e51a2f2b37d5a",
      "bd52db0e3b3244c7a3b26518ec37f28b",
      "9b97cc6006214516a71b1b9d0dfe1eaf",
      "ccb6a906ab114b91852b1618130b8cef",
      "c9c48bd177ad4c5fb58814de56fbc9c0",
      "d6314e60272343e289222bdad45f4de4",
      "851f0af200504c65b9dc33613f61a99e",
      "7d80ede6b2884eb18662ef3617bc8922",
      "675c230f31e14f66a81367f935529eee",
      "96c2f18e238c40c4ae0d7dc551bd9900",
      "c4ed4a7b8557470f8554b735c855a8cf",
      "edd848e6fea046cf8d7bdcb2f927feeb",
      "54c06b2a28fc450a911826930688c6d3",
      "d075711b8ac2409aba8336798249bb04",
      "d03fbde826754cbea168351699e90131",
      "946cfe7c7b8e4555b78bd374df5bcba9",
      "c0488d4c9e7349f39ee45995439358c8",
      "e2ac34e9cfa74b6c969c57b1585e3dc1",
      "1610f22765744f569f24e1c43d090e01",
      "abcdf959a69b48bb8b134e97fde507ad",
      "488389ee9487400b8eb29588c72a56ae",
      "880c46d89824418c94e355314d7f50f6",
      "df557406010f45f3a1aa07dc23845309",
      "e4a9ffaf20fc4a16ac26bb6a846421b9",
      "199350df4fe94f798a75537437ce8a1a",
      "2769ab0280844e9eaaa63302cc700ee6",
      "6dbee5a00f684588a421c4c19f7fa87e",
      "af9a5b617da04387be10c9027b5c6dff",
      "d67851f8b9314ff6910d2035d9971e53",
      "e7bfe24d528044959ee43f7dac3c7ed7",
      "cc9309d4ec4f48cbaeb5e79233e8a6c6",
      "bbbe6b914f6b49e29f9e544e5d9b19b7",
      "46f7c973010f4b378be01bb935576849",
      "c836d438bb774312a756633bbedbb584",
      "ae2bb9aee9dd4e0eafe589f1ad330f1a",
      "06cc28eac51144969a0c68f94cdcac34",
      "18aa83a74a014b37b9f1cf43ca4e47ab",
      "9a2285d9c33c4142bae1d9c6dac6ffda",
      "9f5e3257c0b340bfaeb6cd831edeb8b3",
      "b5b81e228e4847dfa5328beedce1cda3",
      "ceb69641938f454eb42da414538785df",
      "a3c92d97eb4446e484420bae960f3b47",
      "73e22466e183443dab45b3462859cba5",
      "1f9b979283664bf09e1d3331caecf1a3",
      "d59ee95022c547fc9b8c56f901f573ea",
      "30658efbfb60474e84094f1b9115df2b",
      "7628295bb4cb47c9a11803a508fc6db8",
      "0972c0e56ce443d2a5b0ac46101f0580",
      "f86274cc747342a497361f565c322d2a",
      "c2c59f34d065485da5d3c384ee8fb8c9",
      "8c35920c83ef4497bcfe0bb937b85317",
      "5ccf278ce4934412ac17d2dcd194f533",
      "54278bee07454e0ab0a42ae21f7d6a98"
     ]
    },
    "id": "A2hzQLKxVX0z",
    "outputId": "6d98743c-5659-4802-d80c-9edb65f0fae3"
   },
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "import gradio as gr\n",
    "from time import time\n",
    "import re\n",
    "\n",
    "class SummarizerTxt:\n",
    "    def __init__(self):\n",
    "        model_name = \"google/pegasus-xsum\"\n",
    "        self.tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = PegasusForConditionalGeneration.from_pretrained(model_name).to(self.device)\n",
    "        self.chunk_size = 512\n",
    "        self.max_length = 256\n",
    "\n",
    "    def split_into_sentences(self, text):\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', text)\n",
    "        return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "    def chunk_text(self, text):\n",
    "        if not text.strip():\n",
    "            return []\n",
    "\n",
    "        sentences = self.split_into_sentences(text)\n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        current_length = 0\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence_tokens = self.tokenizer(sentence, return_tensors=\"pt\", truncation=False)[\"input_ids\"][0]\n",
    "            sentence_length = len(sentence_tokens)\n",
    "            \n",
    "            if current_length + sentence_length <= self.chunk_size:\n",
    "                current_chunk.append(sentence)\n",
    "                current_length += sentence_length\n",
    "            else:\n",
    "                if current_chunk:\n",
    "                    chunks.append(\" \".join(current_chunk))\n",
    "                current_chunk = [sentence]\n",
    "                current_length = sentence_length\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            \n",
    "        return chunks\n",
    "\n",
    "    def summarize(self, text):\n",
    "        if not text.strip():\n",
    "            return \"Please enter some text to summarize.\"\n",
    "\n",
    "        chunks = self.chunk_text(text)\n",
    "        \n",
    "        if not chunks:\n",
    "            return \"Text is too short to summarize.\"\n",
    "\n",
    "        summaries = []\n",
    "        for chunk in chunks:\n",
    "            inputs = self.tokenizer(\n",
    "                chunk,\n",
    "                truncation=True,\n",
    "                padding=\"longest\",\n",
    "                max_length=self.chunk_size,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(self.device)\n",
    "\n",
    "            summary_ids = self.model.generate(\n",
    "                inputs.input_ids,\n",
    "                attention_mask=inputs.attention_mask,\n",
    "                num_beams=4,\n",
    "                max_length=self.max_length,\n",
    "                min_length=32,\n",
    "                early_stopping=True,\n",
    "                length_penalty=1.0,\n",
    "                no_repeat_ngram_size=3\n",
    "            )\n",
    "            summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "            summaries.append(summary)\n",
    "\n",
    "        return \" \".join(summaries)\n",
    "\n",
    "summarizer = SummarizerTxt()\n",
    "\n",
    "def summarize_text(input_text):\n",
    "    start = time()\n",
    "    result = summarizer.summarize(input_text)\n",
    "    end = time()\n",
    "    time_taken = end - start\n",
    "    return result, f\"{time_taken:.0f} seconds\"\n",
    "    \n",
    "iface = gr.Interface(\n",
    "    fn=summarize_text,\n",
    "    inputs=gr.Textbox(\n",
    "        label=\"Input Text\",\n",
    "        placeholder=\"Enter text to summarize...\",\n",
    "        lines=5\n",
    "    ),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Summary\", lines=3),\n",
    "        gr.Textbox(label=\"Time taken\",\n",
    "            placeholder=\"time...\")\n",
    "    ],\n",
    "    title=\"Text Summarizer\",\n",
    "    description=\"Summarize long texts using Google's Pegasus model\",\n",
    "    examples=[\n",
    "        [\"The Apollo program was NASA's third human spaceflight program, which successfully landed humans on the Moon between 1969 and 1972.\"],\n",
    "        [\"Machine learning is a subset of artificial intelligence that focuses on building systems that learn from data.\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hu7DD1LY2eef"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
